{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "pythonjvsc74a57bd01667d0a8172249a680971e54a51cc48bcc4ce26e0f90d4d3d5797dbbb682fb60",
   "display_name": "Python 3.7.4  ('FiEnv': venv)"
  },
  "metadata": {
   "interpreter": {
    "hash": "1667d0a8172249a680971e54a51cc48bcc4ce26e0f90d4d3d5797dbbb682fb60"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# TD 3 : COINTEGRATION"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "![CentraleSupelec Logo](https://www.centralesupelec.fr/sites/all/themes/cs_theme/medias/common/images/intro/logo_nouveau.jpg)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## But du TD : \n",
    "* Load the “logret_russel1000_pairtrad.csv” and obtain log-prices\n",
    "* Split the date in in-sample (252 days) and out-of-sample (252 days). \n",
    "* Select the subset of stocks that are I(1) in the in-sample.\n",
    "* Select the pair of cointegrated stocks [Bonferroni correction]\n",
    "* Compute the residue of the cointegrated pairs, and characterize with anARMA(p,q)\n",
    "* Check if this mean reversion behaviour persists \n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import random as rd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "import pandas as pd    \n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.arima_model import ARMA\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.tsa.stattools import coint\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "__author__ = \"Colleville Tanguy\"\n",
    "__copyright__ = \"None\"\n",
    "__credits__ = [\"None\"]\n",
    "__license__ = \"None\"\n",
    "__version__ = \"1.0.0\"\n",
    "__maintainer__ = \"Colleville Tanguy\"\n",
    "__email__ = \"tanguy.colleville@student-cs.fr\"\n",
    "__status__ = \"Dev\""
   ]
  },
  {
   "source": [
    "## 1. Load and split the dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Indice_r c'est pour dire qu'on travaille avec le log return $$\\newline$$\n",
    "Indice_p pour dire qu'on travaille avec le log price"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_r=pd.read_csv(\"logret_russel1000_pairtrad.csv\",index_col=0)\n",
    "df_p=df_r.cumsum(axis=0)##to get log price\n",
    "data_p=df_p.copy()\n",
    "data_r=df_r.copy()"
   ]
  },
  {
   "source": [
    "## Passer log return à log price --> df.cumsum(axis=0)\n",
    "## Passer log price à log return --> np.exp(df)-1"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Attention bien faire gaffe au NAn values le jour du test"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "504\n"
     ]
    }
   ],
   "source": [
    "print(len(df_r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_in,t_out=252,252"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_in_p,d_out_p=data_p[:t_in], data_p[t_in:]\n",
    "d_in_r,d_out_r=data_r[:t_in], data_r[t_in:]"
   ]
  },
  {
   "source": [
    "## 2. Select the subset of stocks that are I(1) in the in-sample."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# en fait la dérivée d\"ordre 1 est elle est faite ==> Log price c'est dérivée d'ordre 1 du log return donc si log return passe addfuller test ça fait dire que le log price est stationnaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "assets=d_in_p.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_p=[]\n",
    "mask_r=[]\n",
    "for asset in assets  :\n",
    "    result_p = adfuller(d_in_p[asset])\n",
    "    result_r = adfuller(d_in_r[asset])\n",
    "    \n",
    "    if result_p[1]>0.01: # SI P-value >0.01 --> ça veut dire stationnaire. Si tu taffes sur le price\n",
    "        mask_p.append(False)\n",
    "    if result_p[1]<0.01 : \n",
    "        mask_p.append(True)\n",
    "\n",
    "        \n",
    "    if result_r[1]<0.01:  \n",
    "        mask_r.append(True)\n",
    "    else : \n",
    "        mask_r.append(False) \n",
    "# Mask un peu plus opti\n",
    "#sel = np.array( [i for i in range(len(d_in_p)) if (adfuller(d_in_r[i])[1]<0.01) and adfuller(d_in_p[i])[1]>0.01] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_i_1=[]\n",
    "for asset in assets  :\n",
    "    result_p = adfuller(d_in_p[asset])\n",
    "    result_r = adfuller(d_in_r[asset])\n",
    "        \n",
    "    if result_r[1]<0.01 and result_p[1]>0.01 :  \n",
    "        mask_i_1.append(True)\n",
    "    else : \n",
    "        mask_i_1.append(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ARE I(1) :  Index(['BPOP', 'BRK-B', 'BXP', 'BXS', 'C', 'CACI', 'CAG', 'CAH', 'CASY', 'CAT',\n       'CB', 'CBSH', 'CBT', 'CCL', 'CFR', 'CHE', 'CHRW', 'CI', 'CIEN', 'CINF',\n       'CKH', 'CL', 'CLI', 'CLX', 'CMA', 'COF', 'COHR', 'COO', 'COP', 'COST',\n       'CPB', 'CPT', 'CR', 'CREE', 'CSCO', 'CSGP', 'CSL', 'CTAS', 'CTL', 'CVS',\n       'CVX', 'CW', 'D', 'DD', 'DE', 'DGX', 'DIS', 'DISH', 'DLTR', 'DOV'],\n      dtype='object')\nARE I(1) bis :  Index(['BPOP', 'BRK-B', 'BXP', 'BXS', 'C', 'CACI', 'CAG', 'CAH', 'CASY', 'CAT',\n       'CB', 'CBSH', 'CBT', 'CCL', 'CFR', 'CHE', 'CHRW', 'CI', 'CIEN', 'CINF',\n       'CKH', 'CL', 'CLI', 'CLX', 'CMA', 'COF', 'COHR', 'COO', 'COP', 'COST',\n       'CPB', 'CPT', 'CR', 'CREE', 'CSCO', 'CSGP', 'CSL', 'CTAS', 'CTL', 'CVS',\n       'CVX', 'CW', 'D', 'DD', 'DE', 'DGX', 'DIS', 'DISH', 'DLTR', 'DOV'],\n      dtype='object')\nARE I(2):  Index([], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "stationnary_assets_1=assets[mask_r]\n",
    "stationnary_assets_1_bis=assets[mask_i_1]\n",
    "stationnary_assets_2=assets[mask_p]\n",
    "print(\"ARE I(1) : \", stationnary_assets_1) ##all\n",
    "print(\"ARE I(1) bis : \", stationnary_assets_1_bis) ##all\n",
    "print(\"ARE I(2): \", stationnary_assets_2) ##all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Index(['BPOP', 'BRK-B', 'BXP', 'BXS', 'C', 'CACI', 'CAG', 'CAH', 'CASY', 'CAT',\n",
       "       'CB', 'CBSH', 'CBT', 'CCL', 'CFR', 'CHE', 'CHRW', 'CI', 'CIEN', 'CINF',\n",
       "       'CKH', 'CL', 'CLI', 'CLX', 'CMA', 'COF', 'COHR', 'COO', 'COP', 'COST',\n",
       "       'CPB', 'CPT', 'CR', 'CREE', 'CSCO', 'CSGP', 'CSL', 'CTAS', 'CTL', 'CVS',\n",
       "       'CVX', 'CW', 'D', 'DD', 'DE', 'DGX', 'DIS', 'DISH', 'DLTR', 'DOV'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "assets[mask_i_1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(252, 50)\n(252, 50)\n"
     ]
    }
   ],
   "source": [
    "print(d_in_p.shape)\n",
    "d_in_p=d_in_p[assets[mask_i_1]]\n",
    "print(d_in_p.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'df_in_log' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-eea0da7ce9bd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf_in_log_p_I1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf_in_log\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0massets\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmask_i_1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'df_in_log' is not defined"
     ]
    }
   ],
   "source": [
    "df_in_log_p_I1=df_in_log[assets[mask_i_1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_p==mask_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diff(Y):\n",
    "    return [Y[i]-Y[i-1] for i in range(1,len(Y))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "index\n",
       "2000-01-03    [0.0026082548276860004, 0.0220099479035581, -0...\n",
       "2000-01-04    [0.0005360555380855003, 0.040754200339728194, ...\n",
       "2000-01-05    [0.05355796887605319, 0.03270356853161209, -0....\n",
       "2000-01-06    [0.0992878412808017, 0.01028531928616339, -0.0...\n",
       "2000-01-07    [0.1081179202417564, 0.037102466784682486, -0....\n",
       "                                    ...                        \n",
       "2000-12-22    [0.24987760138612727, 0.21828930216918996, -0....\n",
       "2000-12-26    [0.2390863816018295, 0.21049270398873435, -0.6...\n",
       "2000-12-27    [0.25740401753281617, 0.19411026708259588, -0....\n",
       "2000-12-28    [0.2740724046112338, 0.18527276650238805, -0.6...\n",
       "2000-12-29    [0.28316005769657754, 0.13590667574574278, -0....\n",
       "Length: 252, dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "df_i2=d_in_p.apply(diff,axis=1)\n",
    "df_i2"
   ]
  },
  {
   "source": [
    "## 3. Select the pair of cointegrated stocks [Bonferroni correction] --> sur les log PRIXXXXX"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "matrice=np.zeros(((len(assets)),len(assets)))\n",
    "N=len(assets)\n",
    "for i,asset_1 in enumerate(assets):\n",
    "    for j,asset_2 in enumerate(assets) :\n",
    "        matrice[i,j]=coint(d_in_p[asset_1],d_in_p[asset_2])[1]# p-value de cointegration des returns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Done in 108.26712942123413 s\n"
     ]
    }
   ],
   "source": [
    "import time as time \n",
    "t1=time.time()\n",
    "Coint_matrice = sorted([(coint(d_in_p[i],d_in_p[j])[1],(i,j)) for i in assets[mask_i_1] for j in assets[mask_i_1] if i!=j])\n",
    "print(f\"Done in {time.time()-t1} s\")"
   ]
  },
  {
   "source": [
    "C'est une liste (p value coint, (index asset_a , index_asset_b))"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(matrice).invert_yaxis()\n",
    "# sns.clustermap(matrice)\n",
    "plt.title(\"Map of the p-values of coint\")\n",
    "plt.xlabel(\"index of stocks\")\n",
    "plt.ylabel(\"index of stocks\")\n",
    "plt.show()"
   ]
  },
  {
   "source": [
    "$ \\alpha_{b}=\\frac{\\alpha_s}{n_{assets}}$ --> Bonferroni threshold"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Bonferroni selection \n",
    "# thr_b=0.01/len(matrice.flatten())## On veut ceux qui ont des p-value supérieur à ça\n",
    "thr_b=0.01/(N*N)## On veut ceux qui ont des p-value supérieur à ça\n",
    "print(thr_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mask_bonferonni=np.zeros((len(matrice),len(matrice)))\n",
    "for i in range(len(matrice)):\n",
    "    for j in range(len(matrice)):\n",
    "        if matrice[i,j]<thr_b and i!=j:\n",
    "            mask_bonferonni[i,j]=True\n",
    "        else : \n",
    "            mask_bonferonni[i,j]=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(mask_bonferonni).invert_yaxis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_true=np.where(mask_bonferonni)\n",
    "pairs_perso=[]\n",
    "for i in range(A_true[0].shape[0]):\n",
    "    print('i = {}, j = {}'.format(A_true[0][i],A_true[1][i]))\n",
    "    pairs_perso.append((A_true[0][i],A_true[1][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = list( filter(lambda x: x[0]<thr_b,Coint_matrice))## on récupère ceux qui respecte la condition de Bonferonni "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_1,stock_2=pairs[0][1]\n",
    "print(stock_1,stock_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(d_in_p[stock_1].values,c=\"orange\",label=f\"{stock_1}\")\n",
    "plt.plot(d_in_p[stock_2].values,c=\"blue\",label=f\"{stock_2}\")\n",
    "plt.xlabel(\"time\")\n",
    "plt.ylabel(\"logprice\")\n",
    "plt.title(\"The 2 survivors to Bonferonni + I(1)\")\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On fait une regression sur ceux qu'on a Xi et Xj et on plot le regressé et celui qui a servi à la régression --> plot ça doit être similaire "
   ]
  },
  {
   "source": [
    "2 variables sont cointregrated if  : \n",
    "$ Y_t - \\beta * X_t = \\epsilon_t $ mais on ne connait pas $\\beta$ du coup on fait une OLS : \n",
    "$ Y_t = \\hat{\\alpha} + \\hat{\\beta} X_t + \\hat{u_t}$\n",
    "d'où  : $\\hat{u_t} = Y_t -\\hat{\\alpha} - \\hat{\\beta} X_t $\n",
    "si elles le sont belles et bien alors $\\hat{u_t}$ est un BB "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## reg var est la valeur de prédiction une fois le modèle de régression linéaire sur stock_2 avec stock_1\n",
    "rgfit = LinearRegression().fit(d_in_p[stock_1].values[np.newaxis].T,d_in_p[stock_2])## on calcul les poids de la relation linéaire de ces deux prix --> on calcul alpha chapeau et beta chapeau \n",
    "rgVar = rgfit.predict(d_in_p[stock_1].values[np.newaxis].T) ##on fait une prédiction de ce que ça donnerait pour le stock_1 on connait maintenant alpha chapeau et beta chapeau on calcul donc la valeur des alpha chap + beta chap * prix stock1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(rgVar,label=r\"$\\hat{\\alpha} + \\hat{\\beta} \\times stock_1$\")\n",
    "plt.plot(d_in_p[stock_2].values,label=f\"real value of {stock_2}\")\n",
    "plt.tick_params(labelsize=14)\n",
    "plt.xlabel('days',fontsize=16)\n",
    "plt.ylabel('log-price',fontsize=16)\n",
    "plt.title('in-sample',fontsize=16)\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "source": [
    "## 4. Compute the residue of the cointegrated pairs, and characterize with an ARMA(p,q)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on calcul le résidu u= priceXi- regVar ## regVar c'est Yi obtenu par regression de PriceXi\n",
    "u = d_in_p[stock_2].values-rgVar # la différence entre la valeur du stock_2 et la valeur prédite à partir du stock_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visual representation of the regression variable\n",
    "plt.plot(u,color='k')\n",
    "plt.fill_between(range(252),0,np.clip(u,0,np.inf))\n",
    "plt.fill_between(range(252),np.clip(u,-np.inf,0),0)\n",
    "plt.xlabel('days',fontsize=16)\n",
    "plt.tick_params(labelsize=14)\n",
    "plt.ylabel(r'$u_t$',fontsize=16)\n",
    "plt.title('in-sample',fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#et on caractérise l'arma process de u "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm.graphics.tsa.plot_acf(u,lags=15)\n",
    "plt.xlabel(r'$lags$',fontsize=16)\n",
    "plt.ylabel('ACF',fontsize=16)\n",
    "plt.tick_params(labelsize=14)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm.graphics.tsa.plot_pacf(u,lags=15)\n",
    "plt.xlabel(r'$lags$',fontsize=16)\n",
    "plt.ylabel('PACF',fontsize=16)\n",
    "plt.tick_params(labelsize=14)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = {}\n",
    "models_ARMA_params=[(4,0,'n'),(4,0,'nc'),\n",
    "          (4,2,'n'),(4,2,'nc'),\n",
    "          (5,0,'n'),(5,0,'nc'),\n",
    "          (4,1,'n'),(4,1,'nc'),\n",
    "          (1,1,'n'),(1,1,'nc'),\n",
    "          (2,1,'n'),(2,1,'nc'),\n",
    "          (1,2,'n'),(1,2,'nc'),\n",
    "          (2,2,'n'),(2,2,'nc'),\n",
    "          (3,3,'n'),(3,3,'nc'),\n",
    "          (3,1,'n'),(3,1,'nc')] \n",
    "for p,q,tend in models_ARMA_params:\n",
    "    try:\n",
    "        #fit an arma (for now without trend)\n",
    "        ft = ARMA(u,order=(p,q)).fit(method='mle',trend=tend)\n",
    "        M[p,q,tend] = ft\n",
    "    except ValueError:\n",
    "        print(p,q,'Maybe not stationary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AIC = pd.DataFrame( [(m,ft.aic,ft.bic) for m,ft in M.items()],columns=['model','AIC',\"BIC\"] ) # colum 1 = param column2 = aic\n",
    "\n",
    "AIC = AIC.assign(dAIC=(AIC.AIC-AIC.AIC.min()))\n",
    "AIC = AIC.assign(dBIC=(AIC.BIC-AIC.BIC.min()))\n",
    "\n",
    "AIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(AIC[\"dAIC\"],label=\"dAIC\",color=\"blue\")\n",
    "plt.plot(AIC[\"dBIC\"],label=\"dBIC\",color=\"green\")\n",
    "# plt.plot(AIC[\"dAIC\"].set_index(\"model\"),label=\"dAIC\",color=\"blue\")\n",
    "# plt.plot(AIC[\"dBIC\"].set_index(\"model\"),label=\"dBIC\",color=\"green\")\n",
    "plt.grid()\n",
    "plt.title(\"dAIC & dBIC evolution\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_interet=[5,2]## 1,2 c'est xemple mais grace à AIC on met les indices des modèles qui nous intéresse\n",
    "for i in index_interet:\n",
    "    p,q,t = AIC.model[i]# p , q ,trend\n",
    "    print(M[p,q,t].summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs = {params: M[params].resid for params in AIC.model[index_interet]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for params,r in rs.items():\n",
    "    sm.graphics.tsa.plot_acf(r, lags=20)\n",
    "    plt.xlabel(r'$lags$',fontsize=16)\n",
    "    plt.ylabel('ACF [residue]',fontsize=16)\n",
    "    plt.tick_params(labelsize=14)\n",
    "    plt.title(params,fontsize=16)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Qtest = []  \n",
    "for (p,q,trend),r in rs.items():\n",
    "    pvalue = sm.stats.acorr_ljungbox(r,lags=[p+q+1],model_df=p+q,return_df=True)['lb_pvalue'][p+q+1]\n",
    "    Qtest.append(( (p,q,trend), pvalue))\n",
    "Qtest = pd.DataFrame( Qtest, columns=['model','residue pvalues'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Qtest"
   ]
  },
  {
   "source": [
    "C'est limite pour (2,1) (5,0) c'est mort "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 5. Check if this mean reversion behaviour persists in the out-of-sample."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgVar = rgfit.predict(data_p[stock_1].values[np.newaxis].T)#on extrapole la regression à t_out mais en etant entraîné sur t_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(rgVar)\n",
    "plt.plot(data_p[stock_2].values)\n",
    "plt.vlines(252,0,0.75,ls='--',color='k',label='today')\n",
    "plt.ylim([0,0.5])\n",
    "plt.xlabel('days',fontsize=16)\n",
    "plt.tick_params(labelsize=14)\n",
    "plt.ylabel(r'log-price',fontsize=16)\n",
    "plt.title('in-sample + out-of-sample',fontsize=16)\n",
    "plt.legend(loc='lower right',fontsize=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## on doit regarder in-out sample Xi  e Vareg in-out et vpor so ça se suit toujours sur un plot. Sinon on fait un adfuller((Xi-regVar)[tin:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adfuller( (data_p[stock_2]-rgVar)[252:] )[1] ## on peut pas garantir que le out_sample est stationnaire car p value est trop grande ## on a fait un test de fuller sur le outsample"
   ]
  }
 ]
}